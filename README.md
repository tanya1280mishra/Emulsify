# ğŸ§ Emulsify: Emotion-Based Music Recommendation System

**Emulsify** is an intelligent system that integrates facial emotion recognition, heart rate variability analysis, and stress prediction to deliver personalized music recommendations that enhance emotional well-being and reduce stress.

---

## ğŸ§  Overview

Emulsify bridges the gap between **mental health support** and **technology** by leveraging computer vision, physiological signals, and machine learning for **context-aware music therapy**.

---

## ğŸ—‚ï¸ Project Structure

### 1. **Stress Prediction Pipeline**

* **Data Collection**: Collect physiological signals and emotion-related data.
* **Preprocessing**: Clean and format data for modeling.
* **Feature Engineering**: Extract meaningful features from raw signals.
* **Label Encoding**: Convert categorical variables into numerical format.
* **Scaling**: Normalize features.
* **Model Design & Training**: Train stress prediction models.
* **Validation & Evaluation**: Assess model performance.

### 2. **Facial Emotion Recognition**

* **Face Detection**: Use Haar Cascade Classifier to detect faces in real-time.
* **Image Preprocessing**: Resize, grayscale, and normalize face images.
* **Emotion Classification**: CNN-based classifier to predict emotions from facial features.

### 3. **Song Recommendation System**

* **Data Collection**: Gather song metadata and user preferences.
* **Feature Engineering**: Extract acoustic and contextual song features.
* **Normalization & Clustering**: K-Means to cluster songs based on emotional profiles.
* **Classification**: LightGBM model for emotion-to-song mapping.
* **Ranking & Recommendation**: Rank songs using popularity and match scores.

---

## ğŸ”„ Combined System Workflow

1. Real-time **Facial Emotion Detection**
2. **Heart Rate Variability Analysis**
3. **Stress Level Prediction**
4. **Emotion Classification**
5. **Music Recommendation**

---

## ğŸ§° Technological Stack

| Component         | Technology             |
| ----------------- | ---------------------- |
| Computer Vision   | OpenCV                 |
| Deep Learning     | Keras, TensorFlow      |
| ML Algorithms     | Scikit-learn, LightGBM |
| Data Manipulation | Pandas                 |

---

## ğŸ¯ Applications

* ğŸµ **Personalized Music Therapy**
* ğŸ’† **Stress & Anxiety Management**
* ğŸ’¡ **Emotional Awareness Tools**
* ğŸ§˜ **Well-being Enhancement Platforms**

---

## ğŸš§ Challenges Addressed

* Accurate **emotion recognition** from facial cues.
* Real-time **stress level prediction** using heart rate data.
* Adaptive and contextual **song recommendation** based on current emotional state.

---

## ğŸ“Œ Key Highlights

* End-to-end integration of **vision**, **bio-signals**, and **recommendation engines**.
* Built with a modular architecture, enabling flexibility in model improvements and extension.
* Supports **real-time processing** for practical deployment in mobile or desktop environments.

---

## ğŸ“ License

This project is for academic and research purposes. Licensing terms can be updated based on deployment requirements.

## ğŸš€ Getting Started

Follow these instructions to set up the project locally for development and testing purposes.

### âœ… Prerequisites

Make sure you have the following installed:

* Python 3.8+
* pip
* Git

Install required Python libraries:

```bash
pip install -r requirements.txt
```

> If `requirements.txt` is not present, install manually:

```bash
pip install opencv-python keras tensorflow scikit-learn pandas lightgbm
```

---

## ğŸ“‚ Project Structure (Typical)

```
Emulsify/
â”œâ”€â”€ face_recognition/
â”‚   â”œâ”€â”€ detector.py
â”‚   â””â”€â”€ emotion_model.h5
â”œâ”€â”€ stress_prediction/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ model.py
â”œâ”€â”€ song_recommendation/
â”‚   â”œâ”€â”€ recommender.py
â”‚   â”œâ”€â”€ clustering_model.pkl
â”‚   â””â”€â”€ songs_dataset.csv
â”œâ”€â”€ combined_system.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸ§ª Usage

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/emulsify.git
cd emulsify
```
## ğŸ“Š Example Output

* Detected Emotion: `Sad`
* Predicted Stress Level: `High`
* ğŸ¶ Recommended Songs:

  * â€œLet It Beâ€ â€“ The Beatles
  * â€œWeightlessâ€ â€“ Marconi Union

---

## ğŸ’¡ Tips

* For better real-time results, run on a GPU-enabled system.
* You can replace the song dataset (`songs_dataset.csv`) with your own music metadata.
* Use a spotify sensor API (like Polar or Fitbit) for live stress detection.
